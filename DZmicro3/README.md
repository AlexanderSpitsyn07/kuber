# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

---

## Ответ

Для обеспечения процесса разработки я бы предложил GitLab CI/CD. Есть возможность установить его как на собственном сервере, так и в облаке (правда за некоторые опции придется доплачивать). Gitlab поддерживает систему контроля версий Git. Предлагает бесплатные частные репозитории для проектов с открытым исходным кодом. Однако, если вы хотите получить доступ к большему количеству функций, вам нужно будет перейти на платную версию.Есть возможность настроить параметр в конфигурации конвейера .gitlab-ci.yml, чтобы GitLab CI/CD автоматически повторно запускает jobs конвейера в случае их сбоя заданное число раз. Запуск сборки по кнопке настраивается через с указанием параметров настраивается через создание файла gitlab-ci, в котором прописаны параметры такого запуска в качестве переменных. Для сборки проекта с помощью GitLab CI достаточно внесение настроек (выполнения инструкций из специального файла) .gitlab-ci.yml, где можно прописать настройки (инструкции) для каждой сборки. GitLab имеет шаблон Auto DevOps, который обеспечивает заранее определенную конфигурацию CI/CD. Это позволяет пользователям автоматически определять, создавать, тестировать, разворачивать и контролировать приложения. При загрузке данных на GitLab требуется ввести пароль и логин на сервере также есть возможность использования SSH-ключей для авторизации. Поддерживается двухфакторная аутентификация, интеграция с пользовательскими каталогами (AD/LDAP), гранулярный доступ к объектам в GitLab, поддержка токенов и SSO. GitLab CI / CD запускает сбору GitLab Runners. Раннеры – это изолированные виртуальные машины, которые выполняют предопределенные шаги через API GitLab CI. Runner осуществляет процесс тестирования и сборки проекта в среде GitLab по заданной инструкции. Репозиторий контейнеров GitLab дает возможность создавать безопасное хранилище кастомных образов контейнеров Docker. Причем для этого не придется задействовать дополнительные инструменты — возможности скачивания и загрузки образов внедрены в среду управления репозиторием Git по умолчанию. Поскольку проект GitLab сначала создавали для собственного использования, то возможность развертывания GitLab на своих серверах была опцией по умолчанию. Можно пользоваться GitLab как в облачном варианте , так и скачать все необходимое и установить этот Вебсервис в себя. gitlab-runner register можно использовать несколько раз (что позволит запускать параллельные сборки), будет несколько раннеров на одном сервере, все настройки в одном конфиге производятся в файле config.toml. GITLAB runner — выполняет тесты при каждом коммите в отдельном Docker контейнере. За счет него реализуется автоматическое тестирование кода.Использование Docker необязательно, есть и другие варианты, однако этот — самый распространенный.

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

---

## Ответ

Самый распространенный на сегодня вариант из открытого ПО это стек ELK (Elasticsearch, Logstash и Kibana), его и предложил бы использовать. Комплекс этих программных продуктов отличное решение для оперативного поиска и устранения неисправностей в программном коде, и очень удобный инструмент для разработчиков особенно тех, кто занимается созданием или внедрением отдельных элементов в крупные проекты. Кроме того, функциональность ELK позволяет его использовать в качестве централизованного хранилища журналов, агрегатора событий с удобной навигацией, аналитической системы с алгоритмом машинного обучения, а также по иным назначениям. Logsatsh в потоковом режиме работает одновременно со множеством разных источников данных (СУБД, файлы, системные логи, веб-приложения и пр.), фильтруя и преобразуя их для отправки в хранилище ES. А NoSQL-природа Elasticsearch (отсутствие схемы) позволяет загружать в него JSON-объекты, которые автоматически индексируются и добавляются в базу поиска. Это позволяет ускорить прототипирование поисковых Big Data решений. Возможность передачи для стабильной передачи данных журнала в центральную систему. Гибкие поисковые фильтры, включая нечеткий поиск, возможности работы с восточными языками (китайский, японский, корейский) и мультиарендность, когда в рамках одного объекта ES можно динамически организовать несколько различных поисковых систем. Благодаря наличию встроенных анализаторов текста Elasticsearch автоматически выполняет токенизацию, лемматизацию, стемминг и прочие преобразования текста для решения NLP-задач, связанных с поиском данных. Kibana – визуальный инструмент для Elasticsearch, чтобы взаимодействовать с данными, которые хранятся в индексах ES. Веб-интерфейс Kibana позволяет быстро создавать и обмениваться динамическими панелями мониторинга, включая таблицы, графики и диаграммы, которые отображают изменения в ES-запросах в реальном времени. 

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

---

## Ответ

Мониторинг микросервисов — часто сложная задача: в режиме реального времени нужно отслеживать как состояние отдельных компонентов, так и состояние системы в целом. Часто помимо технических нужно проверять ещё и бизнес показатели. Предложил бы связку из Prometheus и Grafana. Prometheus — популярный проект с открытым исходных кодом, большая часть компонентов которого написана на Golang, а часть — на Ruby. По сути это  будет всего один бинарный файл, который нужно скачать и запустить вместе с компонентами Prometheus.  Prometheus полностью совместим с Docker и доступен на Docker Hub. 
Соответственно, может быть установлен даже в контейнере, и, само собой на физическом сервере или виртуальной машине. Его основная задача — хранить и мониторить определенные объекты. Объектом может стать что угодно: Linux-сервер, сервер Apache, один из процессов, сервер базы данных и, в том числе, микросервисы. Prometheus собирает и хранит  метрики в виде  временных рядов, т.е. информация о метриках хранится с меткой времени, в которую она была записана. Обычно работает в связке с Grafana, которая предоставляет веб-интерфейс для работы с данными, на основе собранных данных воспроизводит графики.  Grafana позволяет пользователям создавать дашборды с панелями (доски), каждая из которых отображает определенные показатели в течение установленного периода времени. Доски графического интерфейса отлично подходят для запроса метрик с сервера Prometheus и визуализации их на панели мониторинга Grafana.

---

